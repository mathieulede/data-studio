{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('dreams.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n#1 (1957)The one at the Meads's house, where...</td>\n",
       "      <td>alta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n#2 (8/11/67)I'm at a family reunion in a lar...</td>\n",
       "      <td>alta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n#3 (8/1/85)I watch a plane fly past and shor...</td>\n",
       "      <td>alta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n#4 (1985?)Me pulling the green leaves and be...</td>\n",
       "      <td>alta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n#5 (1985?)I'm in a room that reminds me of (...</td>\n",
       "      <td>alta</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content    id\n",
       "0  \\n#1 (1957)The one at the Meads's house, where...  alta\n",
       "1  \\n#2 (8/11/67)I'm at a family reunion in a lar...  alta\n",
       "2  \\n#3 (8/1/85)I watch a plane fly past and shor...  alta\n",
       "3  \\n#4 (1985?)Me pulling the green leaves and be...  alta\n",
       "4  \\n#5 (1985?)I'm in a room that reminds me of (...  alta"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from textblob import TextBlob\n",
    "\n",
    "def textblob_tokenizer(str_input):\n",
    "    blob = TextBlob(str_input.lower())\n",
    "    tokens = blob.words\n",
    "    words = [token.stem() for token in tokens]\n",
    "    return words\n",
    "\n",
    "custom_stopwords = ['did', 'don', 'didn', 'came', 'got', 'going', 'just'] + list(stop_words.ENGLISH_STOP_WORDS)\n",
    "\n",
    "# Vectorize and save into a new dataframe\n",
    "vec = TfidfVectorizer(stop_words=custom_stopwords,\n",
    "                      #tokenizer=textblob_tokenizer,\n",
    "                      max_df=0.95,\n",
    "                      min_df=0.15,\n",
    "                      max_features=1000,\n",
    "                      use_idf=True)\n",
    "\n",
    "# Fit from the 'text' column of our dataframe\n",
    "matrix = vec.fit_transform(df['content'])\n",
    "\n",
    "# Then turn it into a new dataframe\n",
    "results = pd.DataFrame(matrix.toarray(), columns=vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dream</th>\n",
       "      <th>house</th>\n",
       "      <th>know</th>\n",
       "      <th>like</th>\n",
       "      <th>little</th>\n",
       "      <th>look</th>\n",
       "      <th>man</th>\n",
       "      <th>people</th>\n",
       "      <th>room</th>\n",
       "      <th>said</th>\n",
       "      <th>say</th>\n",
       "      <th>think</th>\n",
       "      <th>time</th>\n",
       "      <th>went</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.676375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.169588</td>\n",
       "      <td>0.490429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.218161</td>\n",
       "      <td>0.206112</td>\n",
       "      <td>0.427972</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.373968</td>\n",
       "      <td>0.353822</td>\n",
       "      <td>0.562594</td>\n",
       "      <td>0.406738</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.341879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.368956</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.219787</td>\n",
       "      <td>0.425963</td>\n",
       "      <td>0.201508</td>\n",
       "      <td>0.160203</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.194706</td>\n",
       "      <td>0.202144</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.630381</td>\n",
       "      <td>0.423065</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.288699</td>\n",
       "      <td>0.136573</td>\n",
       "      <td>0.217157</td>\n",
       "      <td>0.627993</td>\n",
       "      <td>0.309472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.131963</td>\n",
       "      <td>0.137004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.569659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133798</td>\n",
       "      <td>0.506361</td>\n",
       "      <td>0.201284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.244634</td>\n",
       "      <td>0.380969</td>\n",
       "      <td>0.403135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.132005</td>\n",
       "      <td>0.531551</td>\n",
       "      <td>0.133073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dream     house      know      like    little      look       man  \\\n",
       "0  0.000000  0.676375  0.000000  0.169588  0.490429  0.000000  0.218161   \n",
       "1  0.000000  0.373968  0.353822  0.562594  0.406738  0.000000  0.000000   \n",
       "2  0.219787  0.425963  0.201508  0.160203  0.000000  0.000000  0.000000   \n",
       "3  0.000000  0.288699  0.136573  0.217157  0.627993  0.309472  0.000000   \n",
       "4  0.000000  0.133798  0.506361  0.201284  0.000000  0.000000  0.000000   \n",
       "\n",
       "     people      room      said    say     think      time      went  \n",
       "0  0.206112  0.427972  0.000000  0.000  0.000000  0.000000  0.000000  \n",
       "1  0.341879  0.000000  0.000000  0.000  0.368956  0.000000  0.000000  \n",
       "2  0.194706  0.202144  0.000000  0.221  0.630381  0.423065  0.000000  \n",
       "3  0.131963  0.137004  0.000000  0.000  0.569659  0.000000  0.000000  \n",
       "4  0.244634  0.380969  0.403135  0.000  0.132005  0.531551  0.133073  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method KMeans.fit of KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=3, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# How many clusters?\n",
    "number_of_clusters=3\n",
    "km = KMeans(n_clusters=number_of_clusters)\n",
    "\n",
    "# Let's fit it!\n",
    "km.fit(matrix)\n",
    "km.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "Cluster 0: room house man dream people went say time know think\n",
      "Cluster 1: said went like know people room time little man house\n",
      "Cluster 2: like people think man know say look room little time\n"
     ]
    }
   ],
   "source": [
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vec.get_feature_names()\n",
    "for i in range(number_of_clusters):\n",
    "    top_ten_words = [terms[ind] for ind in order_centroids[i, :10]]\n",
    "    print(\"Cluster {}: {}\".format(i, ' '.join(top_ten_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n#1 (1957)The one at the Meads's house, where...</td>\n",
       "      <td>alta</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n#2 (8/11/67)I'm at a family reunion in a lar...</td>\n",
       "      <td>alta</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n#3 (8/1/85)I watch a plane fly past and shor...</td>\n",
       "      <td>alta</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n#4 (1985?)Me pulling the green leaves and be...</td>\n",
       "      <td>alta</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n#5 (1985?)I'm in a room that reminds me of (...</td>\n",
       "      <td>alta</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content    id  category\n",
       "0  \\n#1 (1957)The one at the Meads's house, where...  alta         0\n",
       "1  \\n#2 (8/11/67)I'm at a family reunion in a lar...  alta         2\n",
       "2  \\n#3 (8/1/85)I watch a plane fly past and shor...  alta         0\n",
       "3  \\n#4 (1985?)Me pulling the green leaves and be...  alta         0\n",
       "4  \\n#5 (1985?)I'm in a room that reminds me of (...  alta         1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category'] = km.labels_\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "think          4914\n",
       "see            4628\n",
       "say            3549\n",
       "went           3527\n",
       "go             3447\n",
       "said           2730\n",
       "saw            2674\n",
       "thought        2474\n",
       "feel           2102\n",
       "remember       1895\n",
       "know           1879\n",
       "look           1775\n",
       "told           1655\n",
       "knew           1580\n",
       "felt           1422\n",
       "tell           1390\n",
       "wanted         1355\n",
       "walk           1295\n",
       "ask            1293\n",
       "woke           1223\n",
       "asked          1214\n",
       "looked         1208\n",
       "try            1145\n",
       "realize        1138\n",
       "realized       1111\n",
       "put             983\n",
       "guess           889\n",
       "found           866\n",
       "find            827\n",
       "are             817\n",
       "               ... \n",
       "cashed            1\n",
       "patched           1\n",
       "sculptured        1\n",
       "messing           1\n",
       "sorrowfully       1\n",
       "frill             1\n",
       "backhand          1\n",
       "dazedly           1\n",
       "trumpet           1\n",
       "hypothesize       1\n",
       "thinkthe          1\n",
       "smashed           1\n",
       "grade             1\n",
       "falsified         1\n",
       "recite            1\n",
       "dealt             1\n",
       "skinned           1\n",
       "dunked            1\n",
       "deftly            1\n",
       "cursed            1\n",
       "scanned           1\n",
       "peak              1\n",
       "commend           1\n",
       "breeze            1\n",
       "horseback         1\n",
       "squatted          1\n",
       "exaggerated       1\n",
       "overshot          1\n",
       "one               1\n",
       "smart             1\n",
       "Length: 3008, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_to_exclude = ['was', 'have', 'can', 'don', 'just', 'am', \n",
    "                    'will', 'had', 'do', 'want', 'could', 'would', \n",
    "                    'never', 'ever', 'didn', 'did', 'got', 'get', \n",
    "                    'couldn', 'were', 'should', 'started']\n",
    "\n",
    "df['I'] = df.apply(\n",
    "    lambda x: [val.lower() for val in re.findall('(?<= I )[a-zA-Z]+', x['content'])],\n",
    "    axis=1)\n",
    "\n",
    "i_list = pd.Series([element for list_ in df['I'] for element in list_])\n",
    "i_list[~i_list.isin(words_to_exclude)].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "head           372\n",
       "wife           356\n",
       "hand           262\n",
       "face           254\n",
       "name           180\n",
       "house          158\n",
       "car            157\n",
       "back           150\n",
       "arm            138\n",
       "mother         130\n",
       "arms           118\n",
       "friends        116\n",
       "hands          107\n",
       "family         105\n",
       "father         104\n",
       "eyes           102\n",
       "mouth          101\n",
       "friend         100\n",
       "own             98\n",
       "office          95\n",
       "hair            91\n",
       "room            89\n",
       "way             79\n",
       "girlfriend      78\n",
       "penis           76\n",
       "body            72\n",
       "son             72\n",
       "brother         72\n",
       "chest           71\n",
       "parents         63\n",
       "              ... \n",
       "canister         1\n",
       "quota            1\n",
       "tasks            1\n",
       "purchase         1\n",
       "are              1\n",
       "tendency         1\n",
       "blond            1\n",
       "spouse           1\n",
       "pacemaker        1\n",
       "figure           1\n",
       "workout          1\n",
       "mansion          1\n",
       "hardening        1\n",
       "usually          1\n",
       "empty            1\n",
       "specially        1\n",
       "erected          1\n",
       "loud             1\n",
       "dangerous        1\n",
       "ghetto           1\n",
       "excitement       1\n",
       "rock             1\n",
       "certificate      1\n",
       "racing           1\n",
       "rent             1\n",
       "general          1\n",
       "sarcasm          1\n",
       "squad            1\n",
       "drum             1\n",
       "pituitary        1\n",
       "Length: 2006, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['his'] = df.apply(\n",
    "    lambda x: [val.lower() for val in re.findall('(?<= his )[a-zA-Z]+', x['content'])],\n",
    "    axis=1)\n",
    "\n",
    "his_list = pd.Series([element for list_ in df['his'] for element in list_])\n",
    "his_list.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "and              1119\n",
       "to                926\n",
       "that              431\n",
       "i                 337\n",
       "in                280\n",
       "if                246\n",
       "head              222\n",
       "face              219\n",
       "husband           199\n",
       "a                 198\n",
       "up                188\n",
       "about             187\n",
       "back              178\n",
       "mother            177\n",
       "for               160\n",
       "house             157\n",
       "hand              155\n",
       "name              135\n",
       "hair              133\n",
       "how               126\n",
       "what              126\n",
       "the               117\n",
       "on                114\n",
       "room              106\n",
       "as                106\n",
       "out               105\n",
       "car               102\n",
       "because            99\n",
       "with               94\n",
       "she                90\n",
       "                 ... \n",
       "waterbed            1\n",
       "bridal              1\n",
       "bosses              1\n",
       "interrupt           1\n",
       "activlties          1\n",
       "captor              1\n",
       "church              1\n",
       "rock                1\n",
       "frailty             1\n",
       "diamonds            1\n",
       "japanese            1\n",
       "disappearance       1\n",
       "catch               1\n",
       "overnight           1\n",
       "skis                1\n",
       "scruffy             1\n",
       "release             1\n",
       "uplifting           1\n",
       "trained             1\n",
       "curfew              1\n",
       "award               1\n",
       "colored             1\n",
       "nursing             1\n",
       "plays               1\n",
       "train               1\n",
       "magnets             1\n",
       "balance             1\n",
       "counselor           1\n",
       "determined          1\n",
       "mowing              1\n",
       "Length: 2009, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['her'] = df.apply(\n",
    "    lambda x: [val.lower() for val in re.findall('(?<= her )[a-zA-Z]+', x['content'])],\n",
    "    axis=1)\n",
    "\n",
    "his_list = pd.Series([element for list_ in df['her'] for element in list_])\n",
    "his_list.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "see             2772\n",
       "help            1138\n",
       "work             702\n",
       "say              613\n",
       "play             577\n",
       "try              576\n",
       "move             563\n",
       "stop             562\n",
       "stay             543\n",
       "know             540\n",
       "sleep            531\n",
       "sit              508\n",
       "eat              497\n",
       "run              433\n",
       "drive            422\n",
       "call             410\n",
       "buy              407\n",
       "ask              393\n",
       "show             390\n",
       "pick             388\n",
       "meet             385\n",
       "turn             359\n",
       "start            327\n",
       "wait             325\n",
       "figure           319\n",
       "kill             312\n",
       "catch            304\n",
       "visit            302\n",
       "pay              293\n",
       "live             292\n",
       "                ... \n",
       "singing            1\n",
       "justice            1\n",
       "walt               1\n",
       "been               1\n",
       "hands              1\n",
       "logoff             1\n",
       "confirmation       1\n",
       "rack               1\n",
       "zig                1\n",
       "josie              1\n",
       "butthead           1\n",
       "riff               1\n",
       "furiously          1\n",
       "belmont            1\n",
       "batteries          1\n",
       "session            1\n",
       "enfold             1\n",
       "wearing            1\n",
       "munch              1\n",
       "ratify             1\n",
       "nyc                1\n",
       "guards             1\n",
       "implant            1\n",
       "wend               1\n",
       "painting           1\n",
       "sexually           1\n",
       "fragrances         1\n",
       "pointed            1\n",
       "clamber            1\n",
       "theft              1\n",
       "Length: 4151, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_to_exclude = ['the','be','get','go','me','a','do','another','my','take','have',\n",
    "                    'him','her','make','find','leave','them','come','put','look',\n",
    "                    'talk','tell','give','keep','his','walk','this','questions','it','use',\n",
    "                    'myself', 'where', 'our', 'an', 'some', 'let', 'someone', 'one', 'us']\n",
    "\n",
    "df['to'] = df.apply(\n",
    "    lambda x: [val.lower() for val in re.findall('(?<= to )[a-zA-Z]+', x['content'])],\n",
    "    axis=1)\n",
    "\n",
    "i_list = pd.Series([element for list_ in df['to'] for element in list_])\n",
    "i_list[~i_list.isin(words_to_exclude)].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "said            688\n",
       "says            358\n",
       "wanted          252\n",
       "wants           195\n",
       "came            193\n",
       "does            149\n",
       "wasn            147\n",
       "told            140\n",
       "went            136\n",
       "knew            117\n",
       "comes           103\n",
       "looked          100\n",
       "took             93\n",
       "won              93\n",
       "left             91\n",
       "asked            90\n",
       "goes             90\n",
       "gave             89\n",
       "looks            83\n",
       "knows            80\n",
       "put              79\n",
       "must             79\n",
       "thought          79\n",
       "seemed           77\n",
       "really           72\n",
       "saw              69\n",
       "might            65\n",
       "walked           65\n",
       "thinks           65\n",
       "kept             63\n",
       "               ... \n",
       "evidently         1\n",
       "snatched          1\n",
       "mind              1\n",
       "pontificates      1\n",
       "slips             1\n",
       "offended          1\n",
       "expect            1\n",
       "interacted        1\n",
       "cusses            1\n",
       "speak             1\n",
       "laments           1\n",
       "think             1\n",
       "yields            1\n",
       "send              1\n",
       "nuzzled           1\n",
       "ground            1\n",
       "recently          1\n",
       "upset             1\n",
       "admires           1\n",
       "small             1\n",
       "fails             1\n",
       "acknowledge       1\n",
       "added             1\n",
       "entertains        1\n",
       "ruined            1\n",
       "sexually          1\n",
       "ditched           1\n",
       "vocalizes         1\n",
       "stormed           1\n",
       "identifies        1\n",
       "Length: 1295, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_to_exclude = ['was', 'have', 'can', 'don', 'just', 'am', \n",
    "                    'will', 'had', 'do', 'want', 'could', 'would', \n",
    "                    'never', 'ever', 'didn', 'did', 'got', 'get', \n",
    "                    'couldn', 'were', 'should', 'started', 'is', 'has',\n",
    "                    'and', 'doesn', 'gets', 'wouldn',]\n",
    "\n",
    "df['he'] = df.apply(\n",
    "    lambda x: [val.lower() for val in re.findall('(?<= he )[a-zA-Z]+', x['content'])],\n",
    "    axis=1)\n",
    "\n",
    "i_list = pd.Series([element for list_ in df['he'] for element in list_])\n",
    "i_list[~i_list.isin(words_to_exclude)].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "said             589\n",
       "says             286\n",
       "wanted           202\n",
       "wants            141\n",
       "came             130\n",
       "told             119\n",
       "does             109\n",
       "wasn             109\n",
       "gave              87\n",
       "went              86\n",
       "thought           79\n",
       "knew              76\n",
       "took              73\n",
       "left              64\n",
       "comes             63\n",
       "asked             62\n",
       "looked            61\n",
       "won               60\n",
       "goes              60\n",
       "knows             60\n",
       "looks             57\n",
       "saw               57\n",
       "tells             56\n",
       "might             55\n",
       "seemed            54\n",
       "needed            51\n",
       "needs             50\n",
       "thinks            49\n",
       "must              47\n",
       "sees              46\n",
       "                ... \n",
       "hitched            1\n",
       "assigned           1\n",
       "studies            1\n",
       "figure             1\n",
       "mimics             1\n",
       "glanced            1\n",
       "grew               1\n",
       "doddles            1\n",
       "signed             1\n",
       "strokes            1\n",
       "sprays             1\n",
       "storms             1\n",
       "doubted            1\n",
       "closes             1\n",
       "dials              1\n",
       "stand              1\n",
       "shook              1\n",
       "you                1\n",
       "contracted         1\n",
       "connected          1\n",
       "requests           1\n",
       "herself            1\n",
       "rode               1\n",
       "give               1\n",
       "smoked             1\n",
       "applied            1\n",
       "lowered            1\n",
       "misunderstood      1\n",
       "work               1\n",
       "fusses             1\n",
       "Length: 1019, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_to_exclude = ['was', 'have', 'can', 'don', 'just', 'am', \n",
    "                    'will', 'had', 'do', 'want', 'could', 'would', \n",
    "                    'never', 'ever', 'didn', 'did', 'got', 'get', \n",
    "                    'couldn', 'were', 'should', 'started', 'is', 'has',\n",
    "                    'and', 'doesn', 'gets', 'wouldn',]\n",
    "\n",
    "df['she'] = df.apply(\n",
    "    lambda x: [val.lower() for val in re.findall('(?<= she )[a-zA-Z]+', x['content'])],\n",
    "    axis=1)\n",
    "\n",
    "i_list = pd.Series([element for list_ in df['she'] for element in list_])\n",
    "i_list[~i_list.isin(words_to_exclude)].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "long            140\n",
       "happy            93\n",
       "close            92\n",
       "far              90\n",
       "hard             64\n",
       "good             63\n",
       "bad              63\n",
       "well             61\n",
       "big              60\n",
       "and              53\n",
       "fast             49\n",
       "forth            43\n",
       "upset            41\n",
       "angry            37\n",
       "tired            34\n",
       "high             33\n",
       "excited          32\n",
       "people           31\n",
       "small            31\n",
       "nice             29\n",
       "real             29\n",
       "scared           29\n",
       "late             28\n",
       "glad             25\n",
       "mad              23\n",
       "loud             23\n",
       "very             22\n",
       "sad              22\n",
       "cute             21\n",
       "crowded          20\n",
       "               ... \n",
       "left              1\n",
       "naomi             1\n",
       "angrily           1\n",
       "love              1\n",
       "sluggish          1\n",
       "innocuous         1\n",
       "rare              1\n",
       "whoever           1\n",
       "miles             1\n",
       "away              1\n",
       "person            1\n",
       "slight            1\n",
       "goodnight         1\n",
       "breakfast         1\n",
       "hopefully         1\n",
       "typing            1\n",
       "ashley            1\n",
       "thankful          1\n",
       "ms                1\n",
       "amused            1\n",
       "frantic           1\n",
       "satisfactory      1\n",
       "weren             1\n",
       "peculiar          1\n",
       "powerfully        1\n",
       "therefore         1\n",
       "totally           1\n",
       "revolting         1\n",
       "sympathetic       1\n",
       "know              1\n",
       "Length: 934, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_to_exclude = ['i', 'we', 'that', 'he', 'they', 'it', \n",
    "                    'much', 'she', 'the', 'on', 'many', 'as', \n",
    "                    'you', 'there', 'when', 'no', 'my', 'then', \n",
    "                    'in', 'was', 'often', 'to', 'j', 'if',\n",
    "                    'is', 'this', 'gets', 'wouldn',]\n",
    "\n",
    "df['so'] = df.apply(\n",
    "    lambda x: [val.lower() for val in re.findall('(?<= so )[a-zA-Z]+', x['content'])],\n",
    "    axis=1)\n",
    "\n",
    "i_list = pd.Series([element for list_ in df['so'] for element in list_])\n",
    "i_list[~i_list.isin(words_to_exclude)].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "upset            13\n",
       "large             9\n",
       "happy             8\n",
       "angry             8\n",
       "nervous           7\n",
       "anxious           6\n",
       "steep             5\n",
       "curious           4\n",
       "sad               4\n",
       "heavy             4\n",
       "tired             4\n",
       "cold              4\n",
       "dangerous         3\n",
       "attractive        3\n",
       "surprised         3\n",
       "good              3\n",
       "pleasant          3\n",
       "poor              3\n",
       "uncomfortable     2\n",
       "short             2\n",
       "frightened        2\n",
       "frustrated        2\n",
       "long              2\n",
       "hot               2\n",
       "perplexed         2\n",
       "agitated          2\n",
       "distraught        2\n",
       "tall              2\n",
       "unpleasant        2\n",
       "small             2\n",
       "                 ..\n",
       "seriously         1\n",
       "deep              1\n",
       "confident         1\n",
       "helpful           1\n",
       "useful            1\n",
       "stern             1\n",
       "icy               1\n",
       "busy              1\n",
       "strong            1\n",
       "dark              1\n",
       "dejected          1\n",
       "deserted          1\n",
       "rude              1\n",
       "thick             1\n",
       "interested        1\n",
       "fed               1\n",
       "valuable          1\n",
       "weak              1\n",
       "exciting          1\n",
       "turned            1\n",
       "hazy              1\n",
       "modern            1\n",
       "dysfunctional     1\n",
       "slippery          1\n",
       "close             1\n",
       "fond              1\n",
       "unlikely          1\n",
       "impressed         1\n",
       "conspicuous       1\n",
       "brilliant         1\n",
       "Length: 128, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_to_exclude = ['i', 'we', 'that', 'he', 'they', 'it', \n",
    "                    'much', 'she', 'the', 'on', 'many', 'as', \n",
    "                    'you', 'there', 'when', 'no', 'my', 'then', \n",
    "                    'in', 'was', 'often', 'to', 'j', 'if',\n",
    "                    'is', 'this', 'gets', 'wouldn',]\n",
    "\n",
    "df['extremely'] = df.apply(\n",
    "    lambda x: [val.lower() for val in re.findall('(?<= extremely )[a-zA-Z]+', x['content'])],\n",
    "    axis=1)\n",
    "\n",
    "i_list = pd.Series([element for list_ in df['extremely'] for element in list_])\n",
    "i_list[~i_list.isin(words_to_exclude)].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "see           113\n",
       "know           87\n",
       "take           70\n",
       "make           61\n",
       "talk           48\n",
       "buy            34\n",
       "play           27\n",
       "leave          26\n",
       "keep           26\n",
       "stay           25\n",
       "help           23\n",
       "tell           23\n",
       "put            21\n",
       "come           20\n",
       "show           19\n",
       "give           19\n",
       "ask            18\n",
       "say            18\n",
       "try            17\n",
       "stop           16\n",
       "watch          16\n",
       "hear           14\n",
       "marry          14\n",
       "find           14\n",
       "use            13\n",
       "call           13\n",
       "look           12\n",
       "sit            12\n",
       "join           12\n",
       "drive          11\n",
       "             ... \n",
       "park            1\n",
       "send            1\n",
       "belong          1\n",
       "shave           1\n",
       "limber          1\n",
       "compose         1\n",
       "light           1\n",
       "cheer           1\n",
       "signal          1\n",
       "search          1\n",
       "rape            1\n",
       "create          1\n",
       "own             1\n",
       "switch          1\n",
       "repay           1\n",
       "dress           1\n",
       "abduct          1\n",
       "defend          1\n",
       "flirt           1\n",
       "reassure        1\n",
       "drown           1\n",
       "devour          1\n",
       "bet             1\n",
       "cure            1\n",
       "slip            1\n",
       "encourage       1\n",
       "burn            1\n",
       "straighten      1\n",
       "seduce          1\n",
       "paint           1\n",
       "Length: 329, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_to_exclude = ['go', 'get', 'be', 'do', 'have']\n",
    "\n",
    "df['wanted_to'] = df.apply(\n",
    "    lambda x: [val.lower() for val in re.findall('(?<= wanted to )[a-zA-Z]+', x['content'])],\n",
    "    axis=1)\n",
    "\n",
    "i_list = pd.Series([element for list_ in df['wanted_to'] for element in list_])\n",
    "i_list[~i_list.isin(words_to_exclude)].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "said          195\n",
       "wanted        139\n",
       "thought        72\n",
       "knew           70\n",
       "won            69\n",
       "seemed         68\n",
       "left           65\n",
       "looked         64\n",
       "look           63\n",
       "took           61\n",
       "say            53\n",
       "need           53\n",
       "aren           52\n",
       "go             52\n",
       "told           52\n",
       "put            52\n",
       "needed         50\n",
       "know           49\n",
       "think          48\n",
       "both           46\n",
       "saw            46\n",
       "really         45\n",
       "gave           43\n",
       "made           42\n",
       "seem           39\n",
       "may            35\n",
       "used           33\n",
       "called         33\n",
       "leave          31\n",
       "kept           30\n",
       "             ... \n",
       "deserve         1\n",
       "saddled         1\n",
       "wake            1\n",
       "screamed        1\n",
       "cheat           1\n",
       "expecting       1\n",
       "graded          1\n",
       "toyed           1\n",
       "fan             1\n",
       "oohed           1\n",
       "warned          1\n",
       "chasing         1\n",
       "originally      1\n",
       "page            1\n",
       "panic           1\n",
       "assign          1\n",
       "cleaned         1\n",
       "peer            1\n",
       "protest         1\n",
       "earn            1\n",
       "face            1\n",
       "ignore          1\n",
       "respect         1\n",
       "as              1\n",
       "kinda           1\n",
       "projected       1\n",
       "existed         1\n",
       "dole            1\n",
       "clear           1\n",
       "beamed          1\n",
       "Length: 903, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_to_exclude = ['was', 'have', 'can', 'don', 'just', 'am', \n",
    "                    'will', 'had', 'do', 'want', 'could', 'would', \n",
    "                    'never', 'ever', 'didn', 'did', 'got', 'get', \n",
    "                    'couldn', 'were', 'should', 'started', 'is', 'has',\n",
    "                    'and', 'doesn', 'gets', 'wouldn', 'are', 'all', 'weren',\n",
    "                    'went', 'came', 'come', 'must', 'might']\n",
    "\n",
    "df['they'] = df.apply(\n",
    "    lambda x: [val.lower() for val in re.findall('(?<= they )[a-zA-Z]+', x['content'])],\n",
    "    axis=1)\n",
    "\n",
    "i_list = pd.Series([element for list_ in df['they'] for element in list_])\n",
    "i_list[~i_list.isin(words_to_exclude)].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "little         54\n",
       "small          37\n",
       "baby           37\n",
       "big            36\n",
       "very           31\n",
       "large          30\n",
       "movie          25\n",
       "man            22\n",
       "huge           21\n",
       "hotel          20\n",
       "school         17\n",
       "maze           16\n",
       "cat            16\n",
       "child          15\n",
       "giant          14\n",
       "roller         13\n",
       "cross          12\n",
       "hospital       12\n",
       "store          12\n",
       "regular        12\n",
       "good           12\n",
       "normal         11\n",
       "dog            11\n",
       "carnival       11\n",
       "city           11\n",
       "bus            11\n",
       "lot            11\n",
       "black          11\n",
       "real           11\n",
       "white          10\n",
       "               ..\n",
       "slave           1\n",
       "touring         1\n",
       "cello           1\n",
       "mature          1\n",
       "sideways        1\n",
       "stair           1\n",
       "cane            1\n",
       "pageboy         1\n",
       "variation       1\n",
       "decorative      1\n",
       "hawk            1\n",
       "mail            1\n",
       "martin          1\n",
       "mr              1\n",
       "bridge          1\n",
       "handle          1\n",
       "sauna           1\n",
       "haunted         1\n",
       "cocoon          1\n",
       "caftan          1\n",
       "solo            1\n",
       "staircase       1\n",
       "buddha          1\n",
       "cream           1\n",
       "goat            1\n",
       "transformer     1\n",
       "motorboat       1\n",
       "rube            1\n",
       "straight        1\n",
       "postal          1\n",
       "Length: 1665, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_to_exclude = []\n",
    "\n",
    "df['like_a'] = df.apply(\n",
    "    lambda x: [val.lower() for val in re.findall('(?<= like a )[a-zA-Z]+', x['content'])],\n",
    "    axis=1)\n",
    "\n",
    "i_list = pd.Series([element for list_ in df['like_a'] for element in list_])\n",
    "i_list[~i_list.isin(words_to_exclude)].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "man            43\n",
       "big            33\n",
       "lot            30\n",
       "woman          23\n",
       "small          20\n",
       "girl           18\n",
       "sign           16\n",
       "boy            16\n",
       "huge           15\n",
       "little         14\n",
       "group          13\n",
       "picture        13\n",
       "large          13\n",
       "young          12\n",
       "car            11\n",
       "very           10\n",
       "red             9\n",
       "couple          9\n",
       "bunch           9\n",
       "friend          7\n",
       "beautiful       7\n",
       "fellow          7\n",
       "horse           6\n",
       "lady            6\n",
       "name            5\n",
       "few             5\n",
       "black           5\n",
       "number          5\n",
       "white           5\n",
       "policeman       5\n",
       "               ..\n",
       "line            1\n",
       "kid             1\n",
       "norwegian       1\n",
       "handicapped     1\n",
       "typed           1\n",
       "rather          1\n",
       "string          1\n",
       "series          1\n",
       "pool            1\n",
       "slip            1\n",
       "way             1\n",
       "sister          1\n",
       "week            1\n",
       "play            1\n",
       "tail            1\n",
       "stage           1\n",
       "bright          1\n",
       "waterfall       1\n",
       "meteor          1\n",
       "different       1\n",
       "wagon           1\n",
       "sheet           1\n",
       "seat            1\n",
       "hanger          1\n",
       "spring          1\n",
       "watch           1\n",
       "party           1\n",
       "motor           1\n",
       "flasher         1\n",
       "brown           1\n",
       "Length: 324, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_to_exclude = []\n",
    "\n",
    "df['saw_a'] = df.apply(\n",
    "    lambda x: [val.lower() for val in re.findall('(?<= saw a )[a-zA-Z]+', x['content'])],\n",
    "    axis=1)\n",
    "\n",
    "i_list = pd.Series([element for list_ in df['saw_a'] for element in list_])\n",
    "i_list[~i_list.isin(words_to_exclude)].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other          347\n",
       "bathroom       344\n",
       "door           285\n",
       "right          257\n",
       "house          255\n",
       "left           226\n",
       "front          226\n",
       "top            218\n",
       "car            178\n",
       "back           178\n",
       "ground         161\n",
       "side           157\n",
       "next           151\n",
       "beach          115\n",
       "end            107\n",
       "floor          107\n",
       "bottom         104\n",
       "man             96\n",
       "edge            93\n",
       "hospital        93\n",
       "kitchen         93\n",
       "store           86\n",
       "room            82\n",
       "office          81\n",
       "window          79\n",
       "airport         71\n",
       "basement        70\n",
       "woman           70\n",
       "street          63\n",
       "place           58\n",
       "              ... \n",
       "dungeon          1\n",
       "bumper           1\n",
       "xxx              1\n",
       "brown            1\n",
       "details          1\n",
       "lateness         1\n",
       "hills            1\n",
       "wharves          1\n",
       "immediate        1\n",
       "theme            1\n",
       "waking           1\n",
       "receiver         1\n",
       "peculiar         1\n",
       "tracks           1\n",
       "danger           1\n",
       "gray             1\n",
       "perfume          1\n",
       "super            1\n",
       "depressions      1\n",
       "cobbler          1\n",
       "drawer           1\n",
       "formation        1\n",
       "slaughter        1\n",
       "worms            1\n",
       "cia              1\n",
       "creatures        1\n",
       "youngest         1\n",
       "button           1\n",
       "human            1\n",
       "belly            1\n",
       "Length: 1969, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_to_exclude = []\n",
    "\n",
    "df['to_the'] = df.apply(\n",
    "    lambda x: [val.lower() for val in re.findall('(?<= to the )[a-zA-Z]+', x['content'])],\n",
    "    axis=1)\n",
    "\n",
    "i_list = pd.Series([element for list_ in df['to_the'] for element in list_])\n",
    "i_list[~i_list.isin(words_to_exclude)].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dream        827\n",
       "back         656\n",
       "middle       512\n",
       "car          462\n",
       "room         456\n",
       "house        389\n",
       "water        381\n",
       "front        336\n",
       "kitchen      297\n",
       "same         240\n",
       "air          234\n",
       "morning      223\n",
       "living       221\n",
       "bathroom     199\n",
       "basement     165\n",
       "country      126\n",
       "other        118\n",
       "center       117\n",
       "distance     113\n",
       "store        102\n",
       "next         102\n",
       "hall         102\n",
       "parking      100\n",
       "hospital      98\n",
       "way           95\n",
       "first         94\n",
       "sky           93\n",
       "woods         92\n",
       "door          90\n",
       "corner        88\n",
       "            ... \n",
       "unit           1\n",
       "mermaid        1\n",
       "english        1\n",
       "cottage        1\n",
       "research       1\n",
       "backstage      1\n",
       "blank          1\n",
       "custom         1\n",
       "financial      1\n",
       "ticket         1\n",
       "smelly         1\n",
       "always         1\n",
       "tray           1\n",
       "batting        1\n",
       "blanks         1\n",
       "scope          1\n",
       "costume        1\n",
       "sunset         1\n",
       "womb           1\n",
       "blimp          1\n",
       "violent        1\n",
       "designer       1\n",
       "answer         1\n",
       "backwash       1\n",
       "sore           1\n",
       "sub            1\n",
       "bancroft       1\n",
       "waterfall      1\n",
       "value          1\n",
       "bathtubs       1\n",
       "Length: 2108, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_to_exclude = []\n",
    "\n",
    "df['in'] = df.apply(\n",
    "    lambda x: [val.lower() for val in re.findall('(?<= in the )[a-zA-Z]+', x['content'])],\n",
    "    axis=1)\n",
    "\n",
    "i_list = pd.Series([element for list_ in df['in'] for element in list_])\n",
    "i_list[~i_list.isin(words_to_exclude)].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "room            436\n",
       "car             359\n",
       "house           330\n",
       "large           293\n",
       "small           255\n",
       "very            202\n",
       "big             201\n",
       "hospital        135\n",
       "building        114\n",
       "hurry           110\n",
       "chair           108\n",
       "wheelchair      105\n",
       "place           103\n",
       "long            102\n",
       "different        97\n",
       "hotel            95\n",
       "row              85\n",
       "little           84\n",
       "while            84\n",
       "huge             83\n",
       "circle           83\n",
       "store            83\n",
       "bed              82\n",
       "strange          80\n",
       "group            69\n",
       "few              69\n",
       "corner           68\n",
       "restaurant       68\n",
       "play             64\n",
       "dream            60\n",
       "               ... \n",
       "sheaf             1\n",
       "physics           1\n",
       "tri               1\n",
       "sr                1\n",
       "message           1\n",
       "hint              1\n",
       "hollandaise       1\n",
       "seashore          1\n",
       "cover             1\n",
       "meal              1\n",
       "precise           1\n",
       "grumpy            1\n",
       "disagreeable      1\n",
       "frozen            1\n",
       "ravine            1\n",
       "santa             1\n",
       "toga              1\n",
       "furniture         1\n",
       "suppressed        1\n",
       "marlboro          1\n",
       "boom              1\n",
       "casket            1\n",
       "jeering           1\n",
       "gathering         1\n",
       "decade            1\n",
       "hurtful           1\n",
       "monotone          1\n",
       "testy             1\n",
       "makeshift         1\n",
       "youthful          1\n",
       "Length: 1814, dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_to_exclude = []\n",
    "\n",
    "df['in_a'] = df.apply(\n",
    "    lambda x: [val.lower() for val in re.findall('(?<= in a )[a-zA-Z]+', x['content'])],\n",
    "    axis=1)\n",
    "\n",
    "i_list = pd.Series([element for list_ in df['in_a'] for element in list_])\n",
    "i_list[~i_list.isin(words_to_exclude)].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "because         40\n",
       "to              32\n",
       "that            29\n",
       "and             29\n",
       "thing           26\n",
       "house           20\n",
       "place           19\n",
       "dream           19\n",
       "man             18\n",
       "city            17\n",
       "people          13\n",
       "town            12\n",
       "part            11\n",
       "about           10\n",
       "looking          9\n",
       "things           8\n",
       "sort             8\n",
       "feeling          7\n",
       "way              7\n",
       "reason           7\n",
       "lady             7\n",
       "men              6\n",
       "little           6\n",
       "neighborhood     6\n",
       "land             5\n",
       "name             5\n",
       "street           5\n",
       "happened         5\n",
       "one              5\n",
       "noises           5\n",
       "                ..\n",
       "jungle           1\n",
       "sight            1\n",
       "questions        1\n",
       "phenomena        1\n",
       "using            1\n",
       "collection       1\n",
       "engine           1\n",
       "interlude        1\n",
       "weapons          1\n",
       "guys             1\n",
       "piano            1\n",
       "state            1\n",
       "curves           1\n",
       "power            1\n",
       "drunk            1\n",
       "roller           1\n",
       "bicycle          1\n",
       "corridor         1\n",
       "airport          1\n",
       "growths          1\n",
       "shadows          1\n",
       "streets          1\n",
       "environment      1\n",
       "shape            1\n",
       "topic            1\n",
       "boat             1\n",
       "party            1\n",
       "double           1\n",
       "moves            1\n",
       "hour             1\n",
       "Length: 280, dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_to_exclude = []\n",
    "\n",
    "df['strange'] = df.apply(\n",
    "    lambda x: [val.lower() for val in re.findall('(?<= strange )[a-zA-Z]+', x['content'])],\n",
    "    axis=1)\n",
    "\n",
    "i_list = pd.Series([element for list_ in df['strange'] for element in list_])\n",
    "i_list[~i_list.isin(words_to_exclude)].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "room           107\n",
       "small           76\n",
       "building        40\n",
       "large           36\n",
       "store           33\n",
       "car             29\n",
       "big             29\n",
       "house           28\n",
       "bathroom        21\n",
       "huge            20\n",
       "little          19\n",
       "new             18\n",
       "bedroom         18\n",
       "very            17\n",
       "place           16\n",
       "corner          16\n",
       "parking         14\n",
       "closet          14\n",
       "sort            14\n",
       "tiny            14\n",
       "hole            13\n",
       "restaurant      12\n",
       "fight           12\n",
       "wall            12\n",
       "gas             12\n",
       "box             11\n",
       "man             11\n",
       "woman            9\n",
       "garage           9\n",
       "door             9\n",
       "              ... \n",
       "prayer           1\n",
       "girls            1\n",
       "chamber          1\n",
       "den              1\n",
       "slooshing        1\n",
       "hippie           1\n",
       "laundry          1\n",
       "forward          1\n",
       "bear             1\n",
       "safely           1\n",
       "land             1\n",
       "stoplight        1\n",
       "domestic         1\n",
       "disturbance      1\n",
       "dictaphone       1\n",
       "cannon           1\n",
       "round            1\n",
       "crocheted        1\n",
       "particular       1\n",
       "master           1\n",
       "pallet           1\n",
       "trampoline       1\n",
       "structure        1\n",
       "vehicle          1\n",
       "number           1\n",
       "trash            1\n",
       "hot              1\n",
       "chair            1\n",
       "gourmet          1\n",
       "under            1\n",
       "Length: 691, dtype: int64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_to_exclude = []\n",
    "\n",
    "df['into'] = df.apply(\n",
    "    lambda x: [val.lower() for val in re.findall('(?<= into a )[a-zA-Z]+', x['content'])],\n",
    "    axis=1)\n",
    "\n",
    "i_list = pd.Series([element for list_ in df['into'] for element in list_])\n",
    "i_list[~i_list.isin(words_to_exclude)].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a                 6673\n",
       "in                3927\n",
       "going             3295\n",
       "very              1586\n",
       "the               1516\n",
       "at                1368\n",
       "trying            1209\n",
       "there             1195\n",
       "on                1092\n",
       "like              1068\n",
       "just              1059\n",
       "sitting            903\n",
       "not                878\n",
       "with               877\n",
       "walking            762\n",
       "so                 741\n",
       "looking            721\n",
       "talking            694\n",
       "an                 657\n",
       "really             655\n",
       "about              646\n",
       "supposed           609\n",
       "doing              607\n",
       "to                 596\n",
       "getting            595\n",
       "standing           590\n",
       "thinking           561\n",
       "working            555\n",
       "kind               538\n",
       "still              526\n",
       "                  ... \n",
       "double               1\n",
       "barry                1\n",
       "drizzling            1\n",
       "clothing             1\n",
       "simultaneously       1\n",
       "oblivious            1\n",
       "block                1\n",
       "camouflaged          1\n",
       "alfred               1\n",
       "mountain             1\n",
       "enthralled           1\n",
       "unwelcome            1\n",
       "secretive            1\n",
       "termite              1\n",
       "swirming             1\n",
       "finalized            1\n",
       "rhonda               1\n",
       "gloomy               1\n",
       "march                1\n",
       "nibbling             1\n",
       "wicca                1\n",
       "unharmed             1\n",
       "maldeveloped         1\n",
       "buzzed               1\n",
       "cake                 1\n",
       "rewinding            1\n",
       "hairless             1\n",
       "secretary            1\n",
       "accompanying         1\n",
       "psyching             1\n",
       "Length: 4367, dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_to_exclude = []\n",
    "\n",
    "df['was'] = df.apply(\n",
    "    lambda x: [val.lower() for val in re.findall('(?<= was )[a-zA-Z]+', x['content'])],\n",
    "    axis=1)\n",
    "\n",
    "i_list = pd.Series([element for list_ in df['was'] for element in list_])\n",
    "i_list[~i_list.isin(words_to_exclude)].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "little         2775\n",
       "lot            1832\n",
       "small          1752\n",
       "very           1657\n",
       "man            1645\n",
       "big            1619\n",
       "few            1589\n",
       "large          1386\n",
       "woman          1340\n",
       "long           1276\n",
       "bit            1202\n",
       "couple          958\n",
       "good            936\n",
       "huge            916\n",
       "car             890\n",
       "room            883\n",
       "house           810\n",
       "group           737\n",
       "while           703\n",
       "place           674\n",
       "dream           670\n",
       "friend          655\n",
       "girl            604\n",
       "young           585\n",
       "new             568\n",
       "table           503\n",
       "bunch           501\n",
       "sort            478\n",
       "baby            452\n",
       "white           441\n",
       "               ... \n",
       "puny              1\n",
       "continental       1\n",
       "therapy           1\n",
       "scanty            1\n",
       "bushing           1\n",
       "lamacchia         1\n",
       "holy              1\n",
       "delinquent        1\n",
       "knack             1\n",
       "penetrating       1\n",
       "tracked           1\n",
       "putrefying        1\n",
       "lad               1\n",
       "requisition       1\n",
       "martyred          1\n",
       "kneeler           1\n",
       "crawly            1\n",
       "pugilist          1\n",
       "rate              1\n",
       "bog               1\n",
       "rel               1\n",
       "squatting         1\n",
       "synesthete        1\n",
       "lapboard          1\n",
       "sr                1\n",
       "bedsit            1\n",
       "momento           1\n",
       "heralding         1\n",
       "stew              1\n",
       "wholesale         1\n",
       "Length: 7802, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_to_exclude = []\n",
    "\n",
    "df['a'] = df.apply(\n",
    "    lambda x: [val.lower() for val in re.findall('(?<= a )[a-zA-Z]+', x['content'])],\n",
    "    axis=1)\n",
    "\n",
    "i_list = pd.Series([element for list_ in df['a'] for element in list_])\n",
    "i_list[~i_list.isin(words_to_exclude)].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "couch          166\n",
       "bus            107\n",
       "trip            99\n",
       "table           94\n",
       "chair           77\n",
       "bed             76\n",
       "boat            73\n",
       "bicycle         71\n",
       "small           71\n",
       "train           70\n",
       "bench           60\n",
       "street          55\n",
       "big             51\n",
       "high            47\n",
       "hill            46\n",
       "shelf           45\n",
       "little          44\n",
       "date            44\n",
       "large           42\n",
       "wall            41\n",
       "long            40\n",
       "very            40\n",
       "ledge           37\n",
       "piece           36\n",
       "plane           36\n",
       "beach           32\n",
       "pair            30\n",
       "road            30\n",
       "side            30\n",
       "motorcycle      30\n",
       "              ... \n",
       "percentage       1\n",
       "curvy            1\n",
       "term             1\n",
       "fork             1\n",
       "training         1\n",
       "crumpled         1\n",
       "puzzle           1\n",
       "tom              1\n",
       "marble           1\n",
       "rubber           1\n",
       "bow              1\n",
       "barstool         1\n",
       "thursday         1\n",
       "partial          1\n",
       "wind             1\n",
       "fake             1\n",
       "die              1\n",
       "rectangular      1\n",
       "wave             1\n",
       "pump             1\n",
       "germany          1\n",
       "folder           1\n",
       "motorized        1\n",
       "elementary       1\n",
       "prominent        1\n",
       "league           1\n",
       "wood             1\n",
       "loft             1\n",
       "nature           1\n",
       "mummy            1\n",
       "Length: 1067, dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_to_exclude = []\n",
    "\n",
    "df['on_a'] = df.apply(\n",
    "    lambda x: [val.lower() for val in re.findall('(?<= on a )[a-zA-Z]+', x['content'])],\n",
    "    axis=1)\n",
    "\n",
    "i_list = pd.Series([element for list_ in df['on_a'] for element in list_])\n",
    "i_list[~i_list.isin(words_to_exclude)].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "grandfather    77\n",
       "knees          76\n",
       "van            75\n",
       "neighbor       74\n",
       "side           74\n",
       "grandmother    73\n",
       "attention      73\n",
       "wallet         72\n",
       "surprise       71\n",
       "birth          71\n",
       "dress          70\n",
       "housemate      68\n",
       "computer       68\n",
       "partner        68\n",
       "books          67\n",
       "job            66\n",
       "door           66\n",
       "grade          66\n",
       "book           65\n",
       "chest          65\n",
       "shirt          65\n",
       "money          65\n",
       "eye            65\n",
       "penis          64\n",
       "girl           63\n",
       "voice          63\n",
       "camera         60\n",
       "shoulders      58\n",
       "birthday       58\n",
       "dog            58\n",
       "               ..\n",
       "toolbox         1\n",
       "attire          1\n",
       "shenanigans     1\n",
       "internal        1\n",
       "amusing         1\n",
       "texaco          1\n",
       "shoelace        1\n",
       "canna           1\n",
       "pov             1\n",
       "leopard         1\n",
       "garment         1\n",
       "supreme         1\n",
       "droopy          1\n",
       "sat             1\n",
       "ciisc           1\n",
       "foxhole         1\n",
       "candy           1\n",
       "lord            1\n",
       "diaper          1\n",
       "copilot         1\n",
       "equilibrium     1\n",
       "strap           1\n",
       "stamina         1\n",
       "tea             1\n",
       "moby            1\n",
       "method          1\n",
       "hostessing      1\n",
       "environment     1\n",
       "mailing         1\n",
       "passes          1\n",
       "Length: 3497, dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_to_exclude = []\n",
    "\n",
    "df['my'] = df.apply(\n",
    "    lambda x: [val.lower() for val in re.findall('(?<= my )[a-zA-Z]+', x['content'])],\n",
    "    axis=1)\n",
    "\n",
    "i_list = pd.Series([element for list_ in df['my'] for element in list_])\n",
    "i_list[~i_list.isin(words_to_exclude)].value_counts()[90:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "missed          15\n",
       "breakfast       15\n",
       "died            14\n",
       "walked          14\n",
       "too             14\n",
       "your            14\n",
       "with            14\n",
       "room            14\n",
       "arrived         14\n",
       "changed         14\n",
       "met             14\n",
       "those           13\n",
       "really          13\n",
       "difficulty      13\n",
       "used            13\n",
       "sexual          13\n",
       "wanted          13\n",
       "long            13\n",
       "good            13\n",
       "returned        12\n",
       "started         12\n",
       "run             12\n",
       "looked          12\n",
       "us              12\n",
       "broken          11\n",
       "often           11\n",
       "four            11\n",
       "none            11\n",
       "hit             11\n",
       "plenty          11\n",
       "                ..\n",
       "retainers        1\n",
       "pissed           1\n",
       "blonde           1\n",
       "marijuana        1\n",
       "surprised        1\n",
       "hotdogs          1\n",
       "grandpa          1\n",
       "decision         1\n",
       "cats             1\n",
       "volunteered      1\n",
       "declared         1\n",
       "physically       1\n",
       "arrangements     1\n",
       "price            1\n",
       "neglected        1\n",
       "legs             1\n",
       "mis              1\n",
       "uncovered        1\n",
       "switched         1\n",
       "but              1\n",
       "important        1\n",
       "snobbish         1\n",
       "rooms            1\n",
       "stylized         1\n",
       "supposedly       1\n",
       "ajay             1\n",
       "naturally        1\n",
       "groups           1\n",
       "ignored          1\n",
       "mummy            1\n",
       "Length: 1234, dtype: int64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_to_exclude = []\n",
    "\n",
    "df['have'] = df.apply(\n",
    "    lambda x: [val.lower() for val in re.findall('(?<= have )[a-zA-Z]+', x['content'])],\n",
    "    axis=1)\n",
    "\n",
    "i_list = pd.Series([element for list_ in df['have'] for element in list_])\n",
    "i_list[~i_list.isin(words_to_exclude)].value_counts()[90:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the creature is                     3\n",
       "the creature. he                    2\n",
       "this creature was                   2\n",
       "cartoon creature out                2\n",
       "a creature that                     2\n",
       "odd creatures dancing               1\n",
       "sea creature with                   1\n",
       "about creatures.                    1\n",
       "flatfish creature, like             1\n",
       "another creature had                1\n",
       "snake-like creature called          1\n",
       "like creature. another              1\n",
       "mechanical/animal creature under    1\n",
       "this creature to                    1\n",
       "these creatures outside.            1\n",
       "like creature with                  1\n",
       "its creature-hood, if               1\n",
       "pony-like creature. i               1\n",
       "crazed creature that                1\n",
       "foreign creature which              1\n",
       "amoeba creatures attacking          1\n",
       "little creature, a                  1\n",
       "a creature i                        1\n",
       "dragon creature. i                  1\n",
       "these creatures are                 1\n",
       "slug-like creatures in              1\n",
       "some creature being                 1\n",
       "demon-like creatures with           1\n",
       "space creature would                1\n",
       "the creature was                    1\n",
       "                                   ..\n",
       "little creature for                 1\n",
       "little creatures. i                 1\n",
       "a creature sort                     1\n",
       "of creature there                   1\n",
       "ghost-like creatures came           1\n",
       "leach-like creature on              1\n",
       "the creatures. i                    1\n",
       "bear/cat/monkey creature in         1\n",
       "monster-like creatures. wundt       1\n",
       "amoeba creature has                 1\n",
       "the creature and                    1\n",
       "the creature flies                  1\n",
       "funny creatures that                1\n",
       "these creatures, like               1\n",
       "these creatures were                1\n",
       "water creatures in                  1\n",
       "these creatures, a                  1\n",
       "useful creatures. as                1\n",
       "the creature leaped                 1\n",
       "of creatures like                   1\n",
       "a creature. i                       1\n",
       "half creature (sort                 1\n",
       "female creatures. they              1\n",
       "a creature somewhat                 1\n",
       "brown creature's nose               1\n",
       "frog creature stuck                 1\n",
       "night creatures, sort               1\n",
       "\"harry\" creature.\\n(111             1\n",
       "eating creature. we                 1\n",
       "water creatures that                1\n",
       "Length: 178, dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_to_exclude = []\n",
    "\n",
    "df['creature'] = df.apply(\n",
    "    lambda x: [val.lower() for val in re.findall('(?:\\S+\\s)?\\S*creature\\S*(?:\\s\\S+)?', x['content'])],\n",
    "    axis=1)\n",
    "\n",
    "i_list = pd.Series([element for list_ in df['creature'] for element in list_])\n",
    "i_list[~i_list.isin(words_to_exclude)].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the monster comes                5\n",
       "the monster was                  5\n",
       "the monster. i                   4\n",
       "the monster of                   3\n",
       "the monster and                  3\n",
       "the monster could                2\n",
       "a monster from                   2\n",
       "the monster, but                 2\n",
       "see monsters, three              2\n",
       "the monster woman                2\n",
       "a monster. i                     2\n",
       "a monster or                     2\n",
       "more monsters trying             1\n",
       "like monster's den,              1\n",
       "about monsters and               1\n",
       "the monster is                   1\n",
       "things, monsters maybe.          1\n",
       "man monster. we                  1\n",
       "giant monsters deep              1\n",
       "a monster, and                   1\n",
       "horrible monster scared          1\n",
       "a monster largemouth             1\n",
       "the monster face.                1\n",
       "of monster or                    1\n",
       "are monsters to                  1\n",
       "these monsters working           1\n",
       "horrible monster like            1\n",
       "the monster disappeared          1\n",
       "like monsters in                 1\n",
       "a monster in                     1\n",
       "                                ..\n",
       "a monster, was                   1\n",
       "were monsters everywhere.        1\n",
       "the monster in                   1\n",
       "prehistoric monster on           1\n",
       "the monster dies                 1\n",
       "become 'monsters' -              1\n",
       "are monsters in                  1\n",
       "or monsters. i                   1\n",
       "horrid monster when              1\n",
       "sea monsters. i'm                1\n",
       "giant monster and                1\n",
       "a monster onstage                1\n",
       "stuffed monster kind             1\n",
       "the \"monster-sticks\" in          1\n",
       "ugly-looking girl/monsters in    1\n",
       "a monster, taking                1\n",
       "this monster. it                 1\n",
       "five monsters in                 1\n",
       "alien monsters to                1\n",
       "people-like monsters on          1\n",
       "like monsters are                1\n",
       "the monster fish                 1\n",
       "the monster. at                  1\n",
       "huge monster shark               1\n",
       "the monsters. we                 1\n",
       "a monster. we                    1\n",
       "supermen monsters! raul          1\n",
       "\"green monster\" in               1\n",
       "a monster and                    1\n",
       "the monster away.                1\n",
       "Length: 120, dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_to_exclude = []\n",
    "\n",
    "df['monster'] = df.apply(\n",
    "    lambda x: [val.lower() for val in re.findall('(?:\\S+\\s)?\\S*monster\\S*(?:\\s\\S+)?', x['content'])],\n",
    "    axis=1)\n",
    "\n",
    "i_list = pd.Series([element for list_ in df['monster'] for element in list_])\n",
    "i_list[~i_list.isin(words_to_exclude)].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stuffed animals and              6\n",
       "stuffed animals. i               4\n",
       "the animal was                   4\n",
       "stuffed animals.                 3\n",
       "of animals on                    3\n",
       "an animal or                     3\n",
       "other animal that                3\n",
       "the animals were                 3\n",
       "the animals and                  3\n",
       "other animals, including         3\n",
       "the animals i                    3\n",
       "his animal friends               2\n",
       "see animals: a                   2\n",
       "the animal. the                  2\n",
       "the animals are                  2\n",
       "an animal with                   2\n",
       "the animal is                    2\n",
       "small animals in                 2\n",
       "stuffed animals to               2\n",
       "more animals and                 2\n",
       "stuffed animals in               2\n",
       "the animals off                  2\n",
       "an animal on                     2\n",
       "the animals. i                   2\n",
       "stuffed animal. we               2\n",
       "the animals to                   2\n",
       "other animals were               2\n",
       "small animals were               2\n",
       "stuffed animals were             2\n",
       "these animals were               2\n",
       "                                ..\n",
       "exotic animals. lion             1\n",
       "different animals. the           1\n",
       "wild animal, to                  1\n",
       "more animals any                 1\n",
       "other animal -                   1\n",
       "imitation animals, elephants,    1\n",
       "mascot animal. nearly            1\n",
       "the animals, which               1\n",
       "cute animals. it                 1\n",
       "balloon animal of                1\n",
       "the animal from                  1\n",
       "the animal will                  1\n",
       "of animals, i                    1\n",
       "some animals. later              1\n",
       "are animals, little              1\n",
       "the animal, not                  1\n",
       "smelly animals around.           1\n",
       "or animals when                  1\n",
       "little people/animals. one       1\n",
       "the animals, there               1\n",
       "the animal shows                 1\n",
       "wild animals in                  1\n",
       "[imaginary] animals. a           1\n",
       "other animals and                1\n",
       "stuffed animals. as              1\n",
       "on animal behavior               1\n",
       "other animals near               1\n",
       "miniature animals. another       1\n",
       "many animals, esp.               1\n",
       "were animals. so                 1\n",
       "Length: 483, dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_to_exclude = []\n",
    "\n",
    "df['animal'] = df.apply(\n",
    "    lambda x: [val.lower() for val in re.findall('(?:\\S+\\s)?\\S*animal\\S*(?:\\s\\S+)?', x['content'])],\n",
    "    axis=1)\n",
    "\n",
    "i_list = pd.Series([element for list_ in df['animal'] for element in list_])\n",
    "i_list[~i_list.isin(words_to_exclude)].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a place to                 182\n",
       "a place where              133\n",
       "took place in               98\n",
       "the place where             94\n",
       "a place that                88\n",
       "the place was               59\n",
       "the place is                55\n",
       "the place. i                32\n",
       "the place and               32\n",
       "this place is               32\n",
       "no place to                 26\n",
       "a place with                25\n",
       "a place like                25\n",
       "the place that              25\n",
       "takes place in              24\n",
       "took place at               24\n",
       "a place for                 23\n",
       "a place in                  23\n",
       "the place i                 22\n",
       "this place where            20\n",
       "the place we                20\n",
       "this place that             18\n",
       "one place to                18\n",
       "taking place in             17\n",
       "this place was              16\n",
       "a place i                   15\n",
       "good place to               14\n",
       "in place of                 14\n",
       "my place. i                 12\n",
       "the place to                12\n",
       "                          ... \n",
       "the places, it               1\n",
       "the places is                1\n",
       "find someplace close         1\n",
       "in place.\\n(357              1\n",
       "been replaced. the           1\n",
       "one place of                 1\n",
       "shallow place and            1\n",
       "one place that's             1\n",
       "they placed me               1\n",
       "no place that                1\n",
       "open place like              1\n",
       "food place -                 1\n",
       "restaurant place that        1\n",
       "your replacement, just       1\n",
       "accident someplace -         1\n",
       "drums someplace. so          1\n",
       "semi-desert place. he        1\n",
       "at places across             1\n",
       "this place. maybe            1\n",
       "had replaced it              1\n",
       "taking place under           1\n",
       "eerie place.                 1\n",
       "prominent places. there      1\n",
       "them replace some            1\n",
       "food place. i                1\n",
       "and placed where             1\n",
       "place was                    1\n",
       "shop/tourist place that      1\n",
       "various places. maybe        1\n",
       "secret place where           1\n",
       "Length: 2967, dtype: int64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_to_exclude = []\n",
    "\n",
    "df['place'] = df.apply(\n",
    "    lambda x: [val.lower() for val in re.findall('(?:\\S+\\s)?\\S*place\\S*(?:\\s\\S+)?', x['content'])],\n",
    "    axis=1)\n",
    "\n",
    "i_list = pd.Series([element for list_ in df['place'] for element in list_])\n",
    "i_list[~i_list.isin(words_to_exclude)].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "to the                    995\n",
       "seemed to be              983\n",
       "going to be               796\n",
       "back to the               734\n",
       "answers to questions      663\n",
       "go to the                 624\n",
       "up to the                 623\n",
       "trying to get             604\n",
       "went to the               568\n",
       "seems to be               554\n",
       "supposed to be            524\n",
       "on top of                 498\n",
       "i told him                495\n",
       "seem to be                487\n",
       "had to go                 463\n",
       "i told her                458\n",
       "the top of                389\n",
       "down to the               346\n",
       "going to have             317\n",
       "going to go               316\n",
       "over to the               299\n",
       "out to the                296\n",
       "get to the                287\n",
       "go into the               282\n",
       "next to the               273\n",
       "have to go                273\n",
       "went into the             259\n",
       "going to get              248\n",
       "want to go                248\n",
       "back into the             245\n",
       "                         ... \n",
       "him to something.           1\n",
       "go to pet                   1\n",
       "preparations to drive,      1\n",
       "supply store.               1\n",
       "was too great,              1\n",
       "child to the                1\n",
       "a burrito. people           1\n",
       "issued to her.              1\n",
       "bag to carry                1\n",
       "promised to save            1\n",
       "on to more                  1\n",
       "all to move                 1\n",
       "idea to take                1\n",
       "want to; it's               1\n",
       "park, touching the          1\n",
       "not too disappointed3.      1\n",
       "there too; she              1\n",
       "talks to him,               1\n",
       "valley to where             1\n",
       "to ponce                    1\n",
       "a store right               1\n",
       "mall store, where           1\n",
       "back to answer              1\n",
       "bag to see                  1\n",
       "expected to play            1\n",
       "dream) to see               1\n",
       "another town, was           1\n",
       "order to sit                1\n",
       "begin to improvise          1\n",
       "over to hand                1\n",
       "Length: 74984, dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_to_exclude = []\n",
    "\n",
    "df['to'] = df.apply(\n",
    "    lambda x: [val.lower() for val in re.findall('(?:\\S+\\s)?\\S*to\\S*(?:\\s\\S+)?', x['content'])],\n",
    "    axis=1)\n",
    "\n",
    "i_list = pd.Series([element for list_ in df['to'] for element in list_])\n",
    "i_list[~i_list.isin(words_to_exclude)].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "i don't know                  1848\n",
       "i don't remember               919\n",
       "i don't want                   587\n",
       "to do with                     466\n",
       "the door and                   442\n",
       "i don't think                  347\n",
       "i don't have                   265\n",
       "the window and                 229\n",
       "to do it                       206\n",
       "i do not                       202\n",
       "the door. i                    188\n",
       "i don't like                   171\n",
       "to do something                169\n",
       "walking down the               157\n",
       "i don't know.                  156\n",
       "to do the                      138\n",
       "to do. i                       129\n",
       "walking down a                 128\n",
       "the door to                    126\n",
       "i don't recall                 123\n",
       "to do this                     122\n",
       "to do it.                      120\n",
       "walk down the                  118\n",
       "go down the                    118\n",
       "to do a                        116\n",
       "to do that                     111\n",
       "i don't really                 108\n",
       "i don't know,                  106\n",
       "to do that.                    105\n",
       "i don't even                    86\n",
       "                              ... \n",
       "and downstairs together,         1\n",
       "or done brain                    1\n",
       "going down.                      1\n",
       "proceeded downstairs and         1\n",
       "the window who                   1\n",
       "will do that.                    1\n",
       "mcdonalds down there\"            1\n",
       "you doing to                     1\n",
       "ibuprofen doesn't really         1\n",
       "no door or                       1\n",
       "were outdoors. when              1\n",
       "came down, and                   1\n",
       "don't fuss.                      1\n",
       "it down. she's                   1\n",
       "hot dog eating                   1\n",
       "the door, yelling,               1\n",
       "book does take                   1\n",
       "my dog's illness.3.              1\n",
       "these double doors               1\n",
       "big window. i                    1\n",
       "cabinets down at                 1\n",
       "it down after                    1\n",
       "goes down our                    1\n",
       "is doing. long                   1\n",
       "or condor--comes close           1\n",
       "days down. i                     1\n",
       "storekeepers (don't know),       1\n",
       "began doing that.                1\n",
       "cast downstream towards          1\n",
       "can do high,                     1\n",
       "Length: 23141, dtype: int64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_to_exclude = []\n",
    "\n",
    "df['do'] = df.apply(\n",
    "    lambda x: [val.lower() for val in re.findall('(?:\\S+\\s)?\\S*do\\S*(?:\\s\\S+)?', x['content'])],\n",
    "    axis=1)\n",
    "\n",
    "i_list = pd.Series([element for list_ in df['do'] for element in list_])\n",
    "i_list[~i_list.isin(words_to_exclude)].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>away</th>\n",
       "      <th>big</th>\n",
       "      <th>car</th>\n",
       "      <th>door</th>\n",
       "      <th>dream</th>\n",
       "      <th>friend</th>\n",
       "      <th>good</th>\n",
       "      <th>home</th>\n",
       "      <th>house</th>\n",
       "      <th>kind</th>\n",
       "      <th>...</th>\n",
       "      <th>thought</th>\n",
       "      <th>time</th>\n",
       "      <th>told</th>\n",
       "      <th>trying</th>\n",
       "      <th>walk</th>\n",
       "      <th>walking</th>\n",
       "      <th>way</th>\n",
       "      <th>went</th>\n",
       "      <th>woman</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.258667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.094141</td>\n",
       "      <td>0.032429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.265413</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074691</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.081383</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.041944</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.038309</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042342</td>\n",
       "      <td>0.074287</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073788</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.080943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121664</td>\n",
       "      <td>0.013970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.082889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.08604</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073401</td>\n",
       "      <td>0.087283</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.027386</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028726</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027646</td>\n",
       "      <td>0.024252</td>\n",
       "      <td>0.028838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028771</td>\n",
       "      <td>0.096355</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105698</td>\n",
       "      <td>0.024124</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       away  big       car     door     dream    friend  good      home  \\\n",
       "0  0.000000  0.0  0.000000  0.00000  0.000000  0.000000   0.0  0.000000   \n",
       "1  0.000000  0.0  0.265413  0.00000  0.000000  0.000000   0.0  0.000000   \n",
       "2  0.041944  0.0  0.000000  0.00000  0.038309  0.000000   0.0  0.042342   \n",
       "3  0.082889  0.0  0.000000  0.08604  0.000000  0.000000   0.0  0.000000   \n",
       "4  0.027386  0.0  0.028726  0.00000  0.000000  0.027996   0.0  0.027646   \n",
       "\n",
       "      house      kind    ...      thought      time  told  trying  walk  \\\n",
       "0  0.258667  0.000000    ...     0.000000  0.000000   0.0     0.0   0.0   \n",
       "1  0.074691  0.000000    ...     0.000000  0.000000   0.0     0.0   0.0   \n",
       "2  0.074287  0.000000    ...     0.000000  0.073788   0.0     0.0   0.0   \n",
       "3  0.073401  0.087283    ...     0.000000  0.000000   0.0     0.0   0.0   \n",
       "4  0.024252  0.028838    ...     0.028771  0.096355   0.0     0.0   0.0   \n",
       "\n",
       "   walking       way      went     woman     words  \n",
       "0      0.0  0.000000  0.000000  0.094141  0.032429  \n",
       "1      0.0  0.081383  0.000000  0.000000  0.028092  \n",
       "2      0.0  0.080943  0.000000  0.121664  0.013970  \n",
       "3      0.0  0.000000  0.000000  0.000000  0.013804  \n",
       "4      0.0  0.105698  0.024124  0.000000  0.009121  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "custom_stopwords = ['did', 'don', 'didn', 'said', 'thee', 'ye', 'came', 'got',\n",
    "                    'like', 'going', 'come', 'feel', 'getting', 'just', 'want',\n",
    "                    'wanted'] + list(stop_words.ENGLISH_STOP_WORDS)\n",
    "\n",
    "\n",
    "vec = TfidfVectorizer(\n",
    "    use_idf=True,\n",
    "    min_df=0.1,\n",
    "    norm='l1',\n",
    "    stop_words=custom_stopwords)\n",
    "matrix = vec.fit_transform(df['content'].str.replace(\"\\d\", \"\"))\n",
    "vocab = vec.get_feature_names()\n",
    "wordcount_df = pd.DataFrame(matrix.toarray(), columns=vocab)\n",
    "wordcount_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
